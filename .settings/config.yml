model:
  input_layers: 2
  output_layers: 2
  amount_of_dropout: 0.2
  hidden_size: 500
  initialization: "he_normal" # : Gaussian initialization scaled by fan-in (He et al., 2014)
  number_of_chars: 100
  max_input_len: 60
  inverted: True
  loss: 'categorical_crossentropy'
  optimizer: 'adam'

# Optimal hyperparameters from hyperas tuning = {u'epochs': 250, u'optimizer': u'adam', u'batch_size': 300}
training:
  batch_size: 300
  epochs: 300
  steps_per_epoch: 255000 # = number of unique samples / batch size = 76,415,055 / 300 = 254,717
  validation_steps: 10
  number_of_iterations: 10
